{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPt3U0iv44zu8NJtWakSnBW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mitr-yuzr/Mirai-NLP-Notebook/blob/main/mirai_nlp_gpt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mirai-NLP-GPT2\n",
        "\n",
        "___\n",
        "\n",
        "> 基于[gpt2-chinese模型](https://github.com/Morizeyao/GPT2-Chinese)的文本生成语言模型训练笔记本\n",
        "\n",
        "作者 **Mitr-yuzr**  \n",
        "GITHUB: [Mitr-yuzr](https://github.com/Mitr-yuzr)  \n",
        "QQ: 1758919843  \n",
        "EMAIL: craft.yuzr@qq.com  \n",
        "MIRAI FORUM: [@MITR-YUZR](https://mirai.mamoe.net/user/mitr-yuzr)\n"
      ],
      "metadata": {
        "id": "PLCzTKa62D71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 声明\n",
        "\n",
        "___\n",
        "\n",
        "仅供学习用途，禁止用于任何违反法律法规和社区规定的行为，禁止用于商业行为。"
      ],
      "metadata": {
        "id": "8KvvWcr1E_XD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 使用方法\n",
        "\n",
        "___\n",
        "\n",
        "- 收集并导出 `gpt2` 格式数据\n",
        "- 登录 Google 账号并确保 Google Drive 可用\n",
        "- 点击右上角的**连接**，等待分配完成和初始化\n",
        "- 在上方菜单栏中选择**代码执行程序**，在倒数第三项找到**更改运行时类型**，在**硬件加速器**中选择 `GPU`，等待分配完成\n",
        "- 在下方按照提示依序进行初始化、训练和生成"
      ],
      "metadata": {
        "id": "osoNGRsbDBQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 全局变量 { run: \"auto\" }\n",
        "\n",
        "#@markdown ### 模型名字\n",
        "model_name = \"mirai-gpt2\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SSpaYKHULBVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 初始化\n",
        "\n",
        "以下单元格为训练和生成内容前的初始化准备，必须从上往下运行。\n",
        "\n",
        "若为二次训练，则**无需进行 ``下载模型`` 步骤**。"
      ],
      "metadata": {
        "id": "7TlobBOt7eO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 挂载Google Drive\n",
        "#@markdown 训练好的模型都会保存在 ``Google Drive`` 中以方便下载、使用和分享，请自行确保``Google Drive``可以正常使用。\n",
        "\n",
        "#@markdown 若连接时没有自动挂载谷歌硬盘，可运行此单元格进行挂载。\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "92wBh4Z_7Az_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 下载源码\n",
        "#@markdown 可能会需要比较长的时间，等待完成即可。\n",
        "!git clone https://github.com/Morizeyao/GPT2-Chinese\n",
        "%cd GPT2-Chinese\n",
        "!pip install -r requirements.txt\n",
        "!gdown 1iga4-oFO-ST55VnLnVRFmHEavmN_DLeb"
      ],
      "metadata": {
        "id": "C3uopn6r2WEu",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 下载预训练模型 { display-mode: \"form\" }\n",
        "\n",
        "#@markdown 这里使用的是[hhou435](https://github.com/hhou435)大佬提供的通用中文小模型。\n",
        "\n",
        "#@markdown 你可以前往[此处](https://github.com/Morizeyao/GPT2-Chinese#%E6%A8%A1%E5%9E%8B%E5%88%86%E4%BA%AB)下载其他模型 (散文、诗词、对联、歌词、文言文等)，并自行上传到``drive/MyDrive/your_model_name/``文件夹下。\n",
        "\n",
        "#@markdown 若为二次训练 (即已经在GDrive中有训练过的模型)，则无需运行此单元格。\n",
        "\n",
        "%cd /content/drive/MyDrive/\n",
        "!mkdir {model_name}\n",
        "!mkdir {model_name}/pretrain_model\n",
        "%cd /content/drive/MyDrive/{model_name}/pretrain_model\n",
        "\n",
        "!gdown 1J_PV3m2OGseTbIyCfbejY28xaShHGevr\n",
        "!gdown 1MXAXWEDGNRH0wEc-qRFbTGWWTZS7EZ2G\n",
        "!gdown 1g18-G0okJM8NRVy6iDySvNRDigQGysz1\n",
        "\n",
        "%cd /content/GPT2-Chinese"
      ],
      "metadata": {
        "id": "6EZbJl2F86K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 上传数据\n",
        "#@markdown 点击运行，在**输出日志**中会出现上传文件的入口，选择刚刚导出的**gpt2**的数据并上传 (会自动重命名为``train.json``)。\n",
        "\n",
        "#@markdown 请检查确认为gpt2类型 (内容只有一行列表，每项只有内容) 的数据后再上传，否则会出现严重问题。\n",
        "\n",
        "!mkdir '/content/GPT2-Chinese/data'\n",
        "%cd data\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  os.rename(fn, \"train.json\")\n",
        "%cd .."
      ],
      "metadata": {
        "id": "910xI2cOGt-s",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 训练\n",
        "\n",
        "本单元格为训练单元格，请仔细填写好参数后运行本单元格。\n",
        "\n",
        "___"
      ],
      "metadata": {
        "id": "rovs-_W1NL55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  { display-mode: \"form\" }\n",
        "\n",
        "#@markdown ### 模型地址\n",
        "#@markdown 若第一次训练则为 ``pretrain_model``，若二次训练则为上次训练最后的模型的文件夹名 (如: ``model_epoch10``)。\n",
        "pretrain_model_name = \"pretrain_model\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### 切片数量\n",
        "#@markdown 对训练数据进行切片的数量，推荐为 ``数据量 / batch_size / 10``。\n",
        "pieces_num = 5 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ### 批大小\n",
        "#@markdown 每批的数据量，依每条数据的长度进行调整。推荐为 ``2、4、8、16``。\n",
        "\n",
        "#@markdown 合适的批大小可以使训练效果更好，但此项参数过大则会引发内存溢出 (Out of Memory, OOM) 错误。\n",
        "\n",
        "#@markdown 若出现OOM错误，则可以将此参数调小。\n",
        "batch_size = 8 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ### 训练轮数\n",
        "#@markdown 将所有训练数据都训练一遍的次数，依据总数据量进行调整。\n",
        "\n",
        "#@markdown 轮数过少会导致**欠拟合**，轮数过多会导致**过拟合**，合适的轮数可以使训练效果更好。\n",
        "\n",
        "#@markdown 推荐训练一定轮数后生成文本查看效果，若过拟合则使用先前模型，若欠拟合则在当前模型的基础上进行二次训练。\n",
        "epochs = 10 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ### 模型保存间隔\n",
        "#@markdown 每隔多少轮保存一次模型，推荐小一点，以防止过拟合或colab背刺。\n",
        "save_every = 5 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ### 起始轮数\n",
        "#@markdown 若首次训练则填0，若二次训练则填下使用的模型的已训练论数。\n",
        "\n",
        "#@markdown 仅用于文件名方便，不影响训练效果。\n",
        "start_epoch = 0 #@param {type:\"integer\"}\n",
        "\n",
        "!python ./train.py \\\n",
        "  --pretrained_model /content/drive/MyDrive/{model_name}/{pretrain_model_name} \\\n",
        "  --model_config /content/drive/MyDrive/{model_name}/{pretrain_model_name}/config.json \\\n",
        "  --tokenizer_path /content/drive/MyDrive/{model_name}/{pretrain_model_name}/vocab.txt \\\n",
        "  --save_every {save_every} \\\n",
        "  --num_pieces {pieces_num} \\\n",
        "  --raw \\\n",
        "  --epochs {epochs} \\\n",
        "  --batch_size {batch_size} \\\n",
        "  --output_dir /content/drive/MyDrive/{model_name}/ \\\n",
        "  --start_epoch {start_epoch}"
      ],
      "metadata": {
        "id": "qM4f3JcmKmdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 生成文本"
      ],
      "metadata": {
        "id": "XymTh_dw-Sfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 生成参数 { run: \"auto\", display-mode: \"form\" }\n",
        "#@markdown ___\n",
        "\n",
        "#@markdown ### 模型名字\n",
        "model = \"model_epoch10\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### 生成内容开头\n",
        "prefix = \"\\u6211\\u662F\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### 生成长度\n",
        "length = 20 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ### 生成的数量\n",
        "nsamples = 5 #@param {type:\"integer\"}"
      ],
      "metadata": {
        "id": "1WaLsYUpys4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 直接生成 { display-mode: \"form\" }\n",
        "!python ./generate.py \\\n",
        "  --length={length} \\\n",
        "  --nsamples={nsamples} \\\n",
        "  --prefix={prefix} \\\n",
        "  --fast_pattern \\\n",
        "  --model_path /content/drive/MyDrive/{model_name}/{model} \\\n",
        "  --model_config /content/drive/MyDrive/{model_name}/{model}/config.json \\\n",
        "  --tokenizer_path /content/drive/MyDrive/{model_name}/pretrain_model/vocab.txt"
      ],
      "metadata": {
        "id": "WQDKwedoV_fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 生成并保存至本地 { display-mode: \"form\" }\n",
        "!python ./generate.py \\\n",
        "  --length={length} \\\n",
        "  --nsamples={nsamples} \\\n",
        "  --prefix={prefix} \\\n",
        "  --fast_pattern \\\n",
        "  --model_path /content/drive/MyDrive/{model_name}/{model} \\\n",
        "  --model_config /content/drive/MyDrive/{model_name}/{model}/config.json \\\n",
        "  --tokenizer_path /content/drive/MyDrive/{model_name}/pretrain_model/vocab.txt \\\n",
        "  --save_samples\n",
        "\n",
        "from google.colab import files\n",
        "files.download('/content/GPT2-Chinese/samples.txt')"
      ],
      "metadata": {
        "id": "bySdjNNzZAJh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}